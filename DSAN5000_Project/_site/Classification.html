<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>DSAN5000_Project - Decision Tree - Classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">DSAN5000_Project</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html" rel="" target="">
 <span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/anly501/dsan-5000-project-jtjt427/tree/main/codes" rel="" target="">
 <span class="menu-text">Code</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/anly501/dsan-5000-project-jtjt427/tree/main/data" rel="" target="">
 <span class="menu-text">Data</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./Introduction.html" rel="" target="">
 <span class="menu-text">Introduction</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./Data_Gathering.html" rel="" target="">
 <span class="menu-text">Data Gathering</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./Cleaning.html" rel="" target="">
 <span class="menu-text">Data Cleaning</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./Data_Exploration.html" rel="" target="">
 <span class="menu-text">Data Exploration</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./Clustering.html" rel="" target="">
 <span class="menu-text">Clustering</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./Dimensionality_Reduction.html" rel="" target="">
 <span class="menu-text">Dimensionality Reduction</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./Naive_Bayes.html" rel="" target="">
 <span class="menu-text">Naive_Bayes</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-decision-trees" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Decision Trees</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-decision-trees">    
        <li>
    <a class="dropdown-item" href="./classification.html" rel="" target="">
 <span class="dropdown-text">Classification</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./Conclusions.html" rel="" target="">
 <span class="menu-text">Conclusions</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#understanding-decision-treesdt-and-random-forestrf" id="toc-understanding-decision-treesdt-and-random-forestrf" class="nav-link active" data-scroll-target="#understanding-decision-treesdt-and-random-forestrf">Understanding Decision Trees(DT) and Random Forest(RF)</a>
  <ul class="collapse">
  <li><a href="#decision-trees-dt" id="toc-decision-trees-dt" class="nav-link" data-scroll-target="#decision-trees-dt">Decision Trees (DT)</a></li>
  <li><a href="#random-forest-rf" id="toc-random-forest-rf" class="nav-link" data-scroll-target="#random-forest-rf">Random Forest (RF)</a></li>
  </ul></li>
  <li><a href="#label-distribution" id="toc-label-distribution" class="nav-link" data-scroll-target="#label-distribution">Label Distribution</a></li>
  <li><a href="#random-classifier" id="toc-random-classifier" class="nav-link" data-scroll-target="#random-classifier">Random Classifier</a></li>
  <li><a href="#decision-trees" id="toc-decision-trees" class="nav-link" data-scroll-target="#decision-trees">Decision Trees</a>
  <ul class="collapse">
  <li><a href="#grid-search-cv" id="toc-grid-search-cv" class="nav-link" data-scroll-target="#grid-search-cv">Grid Search CV</a></li>
  </ul></li>
  <li><a href="#random-forest" id="toc-random-forest" class="nav-link" data-scroll-target="#random-forest">Random Forest</a>
  <ul class="collapse">
  <li><a href="#feature-importances-in-random-forest" id="toc-feature-importances-in-random-forest" class="nav-link" data-scroll-target="#feature-importances-in-random-forest">Feature Importances in Random Forest</a></li>
  </ul></li>
  <li><a href="#performance-evaluation" id="toc-performance-evaluation" class="nav-link" data-scroll-target="#performance-evaluation">Performance Evaluation</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Decision Tree - Classification</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="understanding-decision-treesdt-and-random-forestrf" class="level2">
<h2 class="anchored" data-anchor-id="understanding-decision-treesdt-and-random-forestrf">Understanding Decision Trees(DT) and Random Forest(RF)</h2>
<section id="decision-trees-dt" class="level3">
<h3 class="anchored" data-anchor-id="decision-trees-dt">Decision Trees (DT)</h3>
<p>Imagine you’re trying to decide where to go on vacation and you have a method of making that decision by asking a series of yes-or-no questions. These might involve considerations like whether you want a beach or a mountain, hot or cold weather, or if you’re looking for adventure or relaxation. Decision Trees work in a very similar way to make predictions or decisions. They split data into branches at each level based on some criteria, with the goal of arriving at a decision by the time you reach the bottom of the tree.</p>
<p>In the context of predicting wildfires, a Decision Tree would look at historical climate data—like temperature, humidity, and wind speed—and learn a series of questions to accurately classify days when a wildfire occurred versus when it did not. The “questions” are based on the features of the data and are selected to best separate the days into two groups: high risk and low risk for a wildfire.</p>
</section>
<section id="random-forest-rf" class="level3">
<h3 class="anchored" data-anchor-id="random-forest-rf">Random Forest (RF)</h3>
<p>A Random Forest takes the Decision Tree idea and creates a ‘forest’ of them. Here’s an analogy: rather than relying on one financial advisor to invest your money, you hire a whole team, and each one has a slightly different strategy. In the end, you go with the majority vote on where to invest. Random Forest does something similar—it builds many Decision Trees (each based on different subsets or aspects of the data), and when it’s time to make a decision, each tree gets a vote. The prediction that the majority of trees agree on is chosen as the final output.</p>
<p>For wildfire prediction, a Random Forest would create many Decision Trees, each looking at different random subsets of climate data and making its own assessment. When new data comes in, each tree makes a prediction, and the most common prediction is taken as the final verdict. This method usually gives you better accuracy and reliability, as it’s less likely to be overly influenced by anomalies in the data (a problem known as overfitting) than a single Decision Tree would be.</p>
<p>In both methods, the idea is to use historical patterns to inform predictions—like looking at past financial market trends to predict future stock movements. They’re designed to capture the complex relationships between different factors that can lead to a wildfire, helping decision-makers to focus their efforts on prevention and preparedness where and when it’s most needed.</p>
</section>
</section>
<section id="label-distribution" class="level2">
<h2 class="anchored" data-anchor-id="label-distribution">Label Distribution</h2>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_fscore_support</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, GridSearchCV</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> plot_tree</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>CA_climate_fire <span class="op">=</span> pd.read_csv(<span class="st">'../data/cleaned-data/CA_climate_fire.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Computing the distribution of the 'fire' variable</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>fire_distribution <span class="op">=</span> CA_climate_fire[<span class="st">'fire'</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the distribution</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>fire_distribution.index, y<span class="op">=</span>fire_distribution.values, palette<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Distribution of Fire Variable'</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Fire Occurrence'</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Proportion'</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>plt.xticks([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="st">'No Fire'</span>, <span class="st">'Fire'</span>])</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/yd/4r94v76j0dnbwz14hzdgtyp40000gn/T/ipykernel_32248/951448314.py:6: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=fire_distribution.index, y=fire_distribution.values, palette='viridis')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="classification_files/figure-html/cell-4-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>The bar plot shows the distribution of the ‘fire’ variable in the dataset, which represents the occurrence of fires. Here are the key observations and their implications for the classification algorithm:</p>
<ol type="1">
<li><strong>Distribution</strong>:
<ul>
<li><strong>No Fire (0)</strong>: Approximately 89.37%</li>
<li><strong>Fire (1)</strong>: Approximately 10.63%</li>
</ul></li>
<li><strong>Imbalance in the Dataset</strong>:
<ul>
<li>There is a significant imbalance in the dataset, with a much higher proportion of ‘No Fire’ instances compared to ‘Fire’ instances.</li>
<li>This imbalance can impact the performance of classification algorithms. Models might become biased towards predicting the majority class (‘No Fire’), potentially resulting in lower sensitivity towards detecting actual fire occurrences.</li>
</ul></li>
<li><strong>Implications for Classification Algorithms</strong>:
<ul>
<li><strong>Decision Tree and Random Forest</strong>: Both these models can be affected by the imbalance in the dataset. While they still showed high accuracy, this could partly be because the models are correctly predicting the majority class most of the time. It’s important to look at other metrics like precision, recall, and the confusion matrix to get a better understanding of the model’s performance, especially its ability to detect the minority class (‘Fire’).</li>
</ul></li>
</ol>
</section>
<section id="random-classifier" class="level2">
<h2 class="anchored" data-anchor-id="random-classifier">Random Classifier</h2>
<p>The random classifier is a basic model that makes predictions by randomly assigning a label to each instance in the dataset. In the context of your wildfire prediction, it randomly guesses whether a given day will have a wildfire or not, without considering any of the input features like temperature or humidity. This model serves as a baseline to understand the lowest threshold of performance that any meaningful model should surpass.</p>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> random_classifier(y_data):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if the series dtype is object, which usually means it's categorical or string</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> y_data.dtype <span class="op">==</span> <span class="st">'object'</span>:</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert string labels to a binary numeric format</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        y_data_numeric <span class="op">=</span> y_data.replace({<span class="st">'No'</span>: <span class="dv">0</span>, <span class="st">'Yes'</span>: <span class="dv">1</span>})</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If it's already numeric, use it as is</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        y_data_numeric <span class="op">=</span> y_data</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the distribution of the labels in the dataset</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    label_distribution <span class="op">=</span> y_data_numeric.value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate random predictions based on the label distribution</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    ypred <span class="op">=</span> np.random.choice(label_distribution.index, </span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>                             size<span class="op">=</span><span class="bu">len</span>(y_data_numeric), </span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>                             p<span class="op">=</span>label_distribution.values)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print the classifier's performance</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"-----INFORMED RANDOM CLASSIFIER-----"</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    count_pred <span class="op">=</span> Counter(ypred)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"count of prediction:"</span>, count_pred.values())</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"probability of prediction:"</span>, [<span class="bu">float</span>(v) <span class="op">/</span> <span class="bu">len</span>(ypred) <span class="cf">for</span> v <span class="kw">in</span> count_pred.values()])</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"accuracy"</span>, accuracy_score(y_data_numeric, ypred))</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate precision, recall, and F-score</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    precision, recall, fscore, _ <span class="op">=</span> precision_recall_fscore_support(y_data_numeric, ypred, average<span class="op">=</span><span class="st">'binary'</span>, zero_division<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"precision, recall, fscore,"</span>, (precision, recall, fscore))</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">BINARY CLASS: INFORMED RANDOM LOAD"</span>)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> CA_climate_fire[<span class="st">'fire'</span>] </span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>random_classifier(y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
BINARY CLASS: INFORMED RANDOM LOAD
-----INFORMED RANDOM CLASSIFIER-----
count of prediction: dict_values([1692, 180])
probability of prediction: [0.9038461538461539, 0.09615384615384616]
accuracy 0.8114316239316239
precision, recall, fscore, (0.07222222222222222, 0.06532663316582915, 0.06860158311345646)</code></pre>
</div>
</div>
<p>The output of the informed random classifier reflects the underlying distribution of the <code>fire</code> label in our dataset.</p>
<ul>
<li><p><strong>Count of prediction</strong>: The classifier predicted “no fire” 1,692 times and “fire” 174 times. This suggests that the dataset likely has a similar distribution, with many more days without fires than with.</p></li>
<li><p><strong>Probability of prediction</strong>: Approximately 90.4% of the time, the classifier predicts “no fire,” and about 9.6% of the time, it predicts “fire.” This is consistent with the actual distribution of labels in the dataset.</p></li>
<li><p><strong>Accuracy</strong>: The accuracy is 81.14%, which seems quite high at first glance. However, this is misleading because if the “no fire” class significantly outnumbers the “fire” class, then a classifier that always predicts “no fire” would also have high accuracy. This is known as the accuracy paradox.</p></li>
<li><p><strong>Precision, recall, fscore</strong>: Precision is around 7.2%, indicating that when the classifier predicts a fire, it’s correct only about 7.2% of the time. Recall is about 6.5%, meaning it correctly identifies 6.5% of the actual fire days. The F1 score, which balances precision and recall, is also low at approximately 7%. These values are much lower than the accuracy, highlighting the issue with imbalanced classes: even with high accuracy, the model’s ability to correctly identify positive instances (fire days) is poor.</p></li>
</ul>
<p>In conclusion, the informed random classifier’s high accuracy is not a good indicator of performance due to class imbalance. The low precision and recall reveal the classifier’s lack of predictive power, as it seldom correctly predicts fire days. This reinforces the need for a more sophisticated model that can handle the imbalance and predict the minority class (fire days) more effectively. These baseline figures set a threshold that any predictive model should aim to exceed, especially in terms of precision and recall, to be genuinely useful for wildfire prediction.</p>
</section>
<section id="decision-trees" class="level2">
<h2 class="anchored" data-anchor-id="decision-trees">Decision Trees</h2>
<p>Our dataset comprises daily climate measurements potentially indicative of wildfire occurrences. After converting categorical ‘fire’ labels to numerical values, let’s handle missing feature data by imputing it with the mean.</p>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the 'fire' column to a dummy variable (0 for 'No', 1 for 'Yes')</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>CA_climate_fire[<span class="st">'fire'</span>] <span class="op">=</span> CA_climate_fire[<span class="st">'fire'</span>].<span class="bu">map</span>({<span class="st">'No'</span>: <span class="dv">0</span>, <span class="st">'Yes'</span>: <span class="dv">1</span>})</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Selecting the relevant features and the target variable</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> CA_climate_fire[[<span class="st">'tempmin'</span>, <span class="st">'tempmax'</span>, <span class="st">'humidity'</span>, <span class="st">'precip'</span>, <span class="st">'windspeed'</span>]]</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> CA_climate_fire[<span class="st">'fire'</span>]</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Handling missing values in the features</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> features.fillna(features.mean())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We then split the dataset, allocating 80% for training and 20% for testing.</p>
<p>We will use <code>GridSearchCV</code> to fine-tune the Decision Tree’s parameters, namely the maximum depth of the tree and the minimum number of samples required to split an internal node. The hyperparameter tuning aimed to balance the model’s complexity with its ability to generalize to new data.</p>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the data into train and test sets</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(features, target, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Decision Tree model</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>dtree <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {<span class="st">'max_depth'</span>: np.arange(<span class="dv">3</span>, <span class="dv">10</span>), <span class="st">'min_samples_split'</span>: np.arange(<span class="dv">2</span>, <span class="dv">10</span>)}</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid Search for parameter tuning</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(dtree, param_grid, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train, y_train)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Best estimator after pruning</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>best_tree <span class="op">=</span> grid_search.best_estimator_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="grid-search-cv" class="level3">
<h3 class="anchored" data-anchor-id="grid-search-cv">Grid Search CV</h3>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extracting results from grid search</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>cv_results <span class="op">=</span> grid_search.cv_results_</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame from the CV results</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>cv_results_df <span class="op">=</span> pd.DataFrame(cv_results)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Filtering the DataFrame for relevant information</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>param_columns <span class="op">=</span> [col <span class="cf">for</span> col <span class="kw">in</span> cv_results_df.columns <span class="cf">if</span> <span class="st">'param_'</span> <span class="kw">in</span> col]</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>score_columns <span class="op">=</span> [<span class="st">'mean_test_score'</span>, <span class="st">'std_test_score'</span>]</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>cv_results_df <span class="op">=</span> cv_results_df[param_columns <span class="op">+</span> score_columns]</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting mean test score for each combination of parameters</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> max_depth <span class="kw">in</span> cv_results_df[<span class="st">'param_max_depth'</span>].unique():</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filter by max_depth</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    temp_df <span class="op">=</span> cv_results_df[cv_results_df[<span class="st">'param_max_depth'</span>] <span class="op">==</span> max_depth]</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    plt.plot(temp_df[<span class="st">'param_min_samples_split'</span>], temp_df[<span class="st">'mean_test_score'</span>], marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="ss">f'Max Depth: </span><span class="sc">{</span>max_depth<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Min Samples Split'</span>)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Mean CV Test Score'</span>)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Decision Tree Hyperparameter Tuning'</span>)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classification_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The visualization above illustrates the process of hyperparameter tuning for the Decision Tree model. It shows the mean cross-validation test score for various combinations of the ‘max_depth’ and ‘min_samples_split’ parameters.</p>
<p>In this plot: - Each line represents a different ‘max_depth’ value. - The x-axis indicates the ‘min_samples_split’ parameter. - The y-axis shows the mean test score obtained during cross-validation.</p>
<p>This visualization helps in understanding how the decision tree’s performance varies with changes in its depth and the minimum number of samples required to split a node, guiding the selection of the best parameters for the model.</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the Pruned Decision Tree</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>,<span class="dv">10</span>))</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>plot_tree(best_tree, filled<span class="op">=</span><span class="va">True</span>, feature_names<span class="op">=</span>features.columns, class_names<span class="op">=</span>[<span class="st">'No Fire'</span>, <span class="st">'Fire'</span>], rounded<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Pruned Decision Tree'</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classification_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><strong>Decision Tree After Hyperparameter Tuning</strong>: This visualization displays the structure of the decision tree after pruning. Each node specifies the condition (based on one of the features) and branches into either ‘Fire’ or ‘No Fire’. The color intensity indicates the majority class in each node.</p>
</section>
</section>
<section id="random-forest" class="level2">
<h2 class="anchored" data-anchor-id="random-forest">Random Forest</h2>
<p>In contrast to the single Decision Tree, the Random Forest model aggregates the decisions of numerous trees, each trained on a random subset of the data, to make its final prediction. This ensemble approach is designed to improve prediction accuracy and robustness.</p>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Training the Random Forest model</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>rf <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>rf.fit(X_train, y_train)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluating the models on the test set</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>dtree_pred <span class="op">=</span> best_tree.predict(X_test)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>rf_pred <span class="op">=</span> rf.predict(X_test)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>dtree_accuracy <span class="op">=</span> accuracy_score(y_test, dtree_pred)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>rf_accuracy <span class="op">=</span> accuracy_score(y_test, rf_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="feature-importances-in-random-forest" class="level3">
<h3 class="anchored" data-anchor-id="feature-importances-in-random-forest">Feature Importances in Random Forest</h3>
<div class="cell" data-execution_count="12">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the feature importances for Random Forest</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>feature_importances <span class="op">=</span> rf.feature_importances_</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> np.argsort(feature_importances)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importances in Random Forest'</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>plt.barh(<span class="bu">range</span>(<span class="bu">len</span>(indices)), feature_importances[indices], color<span class="op">=</span><span class="st">'b'</span>, align<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>plt.yticks(<span class="bu">range</span>(<span class="bu">len</span>(indices)), [features.columns[i] <span class="cf">for</span> i <span class="kw">in</span> indices])</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Relative Importance'</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classification_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The Random Forest model’s feature importance chart illustrates the relative importance of each feature in the Random Forest model. The features are ranked according to their importance in predicting fire occurrences, providing insights into which climatic factors are most influential in the model. Humidity and temperatures (minimum and maximum) appear to be the most influential factors, while precipitation has a minimal impact.</p>
<div class="cell" data-execution_count="13">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Output the results</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Decision Tree Accuracy:"</span>, dtree_accuracy)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Random Forest Accuracy:"</span>, rf_accuracy)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Tree Parameters:"</span>, grid_search.best_params_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Decision Tree Accuracy: 0.872
Random Forest Accuracy: 0.8986666666666666
Best Tree Parameters: {'max_depth': 5, 'min_samples_split': 6}</code></pre>
</div>
</div>
</section>
</section>
<section id="performance-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="performance-evaluation">Performance Evaluation</h2>
<p>In testing, the Decision Tree achieved an accuracy of 87.2%, while the Random Forest outperformed slightly with an accuracy of 89.9%. These results suggest that both models are capable predictors of wildfire occurrences compared to the random classifier, with the Random Forest model having a slight edge.</p>
<p>The analysis indicates that certain climatic factors, such as humidity and temperature, play a more critical role in predicting wildfires than others, such as precipitation. The Random Forest model’s higher accuracy can be attributed to its ensemble approach, which effectively captures the complexities and variabilities in the data.</p>
<p>The Decision Tree’s visualization provides actionable insights, offering an interpretable framework that can be used by decision-makers to understand the underlying patterns leading to wildfire occurrences. The insights gained from feature importances can guide resource allocation for fire prevention and control measures, emphasizing the need for humidity and temperature monitoring.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The comparison of Decision Tree and Random Forest models underscores the value of ensemble learning in handling complex datasets with numerous influencing factors. The Random Forest’s superior performance, albeit marginal, along with its ability to account for feature interactions, makes it a preferable choice for predicting wildfires based on the climatic data provided. Implementing these insights can significantly aid in early warning systems, contributing to the prevention and mitigation of wildfire incidents.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>